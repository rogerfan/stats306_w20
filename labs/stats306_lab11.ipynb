{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11 (3/30): Text Data\n",
    "\n",
    "### Web pages\n",
    "Course page: https://ambujtewari.github.io/teaching/STATS306-Winter2020/\n",
    "\n",
    "Lab page: https://rogerfan.github.io/stats306_w20/\n",
    "\n",
    "### Office Hours\n",
    "    Mondays: 2-4pm, USB 2165\n",
    "    \n",
    "### Contact\n",
    "    Questions on problems: Use the slack discussions\n",
    "    If you need to email me, include in the subject line: [STATS 306]\n",
    "    Email: rogerfan@umich.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(tidyverse)\n",
    "require(stringr)\n",
    "require(lubridate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "You can use https://regex101.com/ to test and develop regexs on example text. Remember that when you transfer them into `R`, you need replace replace every backslash with two, so replace `/` with `//` to escape them for `R`.\n",
    "\n",
    "### Special characters\n",
    "\n",
    "Regex takes advantage of several reserved characters that are used for special functions. \n",
    "\n",
    "`. \\ | ( ) [ ] ^ $ { } * + ?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character classes\n",
    "\n",
    "* `.` matches anything (wildcard)\n",
    "* `[aeiou]` matches a single character in the set provided\n",
    "* `[^aeiou]` matches a single character NOT in the set\n",
    "* `[a-e]` matches a range, equivalent to `[abcde]`\n",
    "\n",
    "#### Shorthand\n",
    "\n",
    "* `\\w` matches a \"word\" character, equivalent to `[a-zA-Z0-9_]`\n",
    "* `\\s` matches any whitespace, including tabs and newlines\n",
    "* `\\d` matches digits, equivalent to `[0-9]`\n",
    "* `\\W`, `\\S`, and `\\D` match the opposite of the lower-case versions\n",
    "\n",
    "#### Special characters\n",
    "\n",
    "* Note that `\\t` and `\\n` match the tab and newline characters. \n",
    "* If you want the \"literal\" versions of any of the reserved characters, you will need to escape them with a backslash `\\`, e.g. `[\\.\\\\\\|]`\n",
    "\n",
    "\n",
    "### Grouping\n",
    "\n",
    "* `()` are used to group patterns together. This can be used with any of the below operators. This can also be used to extract portions of a regex out individually, which we will later learn.\n",
    "* `\\1`, `\\2`, etc. refers to the first, second, etc. group in the match.\n",
    "\n",
    "### Operators\n",
    "\n",
    "* `|` is the OR operator and allows matches of either side\n",
    "* `{}` describes how many times the preceeding character of group must occur:\n",
    "  * `{m}` must occur exactly `m` times\n",
    "  * `{m,n}` must occur between `m` and `n` times, inclusive\n",
    "  * `{m,}` Must occur at least `m` times\n",
    "* `*` means the preceeding character can appear zero or more times, equivalent to `{0,}`\n",
    "* `+` means the preceeding character must appear one or more times, equivalent to `{1,}`\n",
    "* `?` means the preceeding character can appear zero or one time, equivalent to `{0,1}`\n",
    "\n",
    "### Anchors\n",
    "\n",
    "* `^` matches the start of a string (or line)\n",
    "* `$` matches the end of a string (or line)\n",
    "* `\\b` matches a word \"boundary\"\n",
    "* `\\B` matches not word boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solutions\n",
    "\n",
    "Given the corpus of common words in `stringr::words`, create regular expressions that find all words that:\n",
    "\n",
    "- Start with `y` (I've done this one for you)\n",
    "- End with `x`\n",
    "- Are exactly two letters long (don’t cheat by `using str_length`!)\n",
    "- Have ten letters or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = stringr::words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[str_detect(words, \"^y\\\\w*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[str_detect(words, \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[str_detect(words, \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[str_detect(words, \"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create regular expressions to find all words that:\n",
    "\n",
    "- End with `ed`, but not with `eed`\n",
    "- End with `ing` or `ise`\n",
    "- End with the same two-letter sequence they start with (e.g. `church`)\n",
    "- Empirically verify the rule \"i before e except after c\" (use multiple patterns to check this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[str_detect(words, \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[str_detect(words, \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[str_detect(words, \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[str_detect(words, \"\")]\n",
    "words[str_detect(words, \"\")]\n",
    "words[str_detect(words, \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Data\n",
    "\n",
    "The file `reddit_dirty.txt` contains a dataset of reddit comments. To see the first few lines, we can use the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts1 = tibble(\n",
    "    var1 = read_lines(\n",
    "        'https://raw.githubusercontent.com/rogerfan/stats306_w20/master/labs/reddit_dirty.txt'\n",
    "    ))\n",
    "\n",
    "head(posts1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first goal will be to clean up and format this dataset. We want a final dataset that has the variables `postid`, `user`, `body`, and `time`.\n",
    "\n",
    "Some functions to keep in mind are `str_detect`, `str_replace`, and `str_extract`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = c('text', 'text200withnum', '200')\n",
    "\n",
    "str_detect(test, '\\\\d+')\n",
    "str_replace(test, '\\\\d+', 'XX')\n",
    "str_replace(test, '\\\\d+', '')\n",
    "str_extract(test, '\\\\d+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Create a new dataset from `posts1` called `posts2`, where we have added a new variable called `key`. This variable `key` should take on values of `\"postid\"`, `\"user\"`, `\"body\"`, or `\"time\"`, depending on what variable that row is. \n",
    "\n",
    "Remember to use `mutate` when creating new variables. \n",
    "Recall when we used `case_when` to create variables like this, and look into `str_detect` for checking for the different patterns that signal each of the possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts2 = posts1 %>%\n",
    "    ...\n",
    "\n",
    "head(posts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Create a new dataset from `posts2` called `posts3`, where a variable called `postid_num` is added. This variable should be an integer corresponding to the postid number when `key == \"postid\"`, and otherwise should be `NA`. You can use `ifelse` with either `str_extract` or `str_replace` to create this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts3 = posts2 %>%\n",
    "    ...\n",
    "\n",
    "head(posts3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "The following code uses the function `fill` to fill down these `postid_num`'s so now each comment's data is tied together with the same `postid_num`. Using functions we've learned before, create `posts4` from `posts3_fill`, where `posts4` is the wide version of the dataset with variables `postid`, `user`, `body`, and `time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts3_fill = posts3 %>%\n",
    "    fill(postid_num, .direction='down') \n",
    "\n",
    "posts4 = posts3_fill %>%\n",
    "    ...\n",
    "\n",
    "head(posts4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Further process the data by cleaning up the user and body fields to remove the url and \"Comment: \" portions. Also note that in `posts4` above the time variable is a string. You can convert this to a datetime variable using `time = ymd_hms(time)` inside of a mutate (this function is in the package `lubridate`, which you should check out for time- and date-related functions). Store this cleaned data in `posts_clean`. It should look like:\n",
    "```\n",
    "# A tibble: 10,000 x 4\n",
    "   postid user                body                          time               \n",
    "    <dbl> <chr>               <chr>                         <dttm>             \n",
    " 1      1 br_shadow           Thank you for this, there is… 2017-12-25 15:49:08\n",
    " 2      2 Ksalol              They are not to quick actual… 2017-12-25 17:42:50\n",
    " 3      3 itscool83           tell her you guys should han… 2017-12-25 18:54:13\n",
    " 4      4 Glu7enFree          \"Autism is a high honor in t… 2017-12-25 07:48:17\n",
    " 5      5 Theotheogreato      \"You thought a cat was your … 2017-12-25 20:58:08\n",
    " 6      6 Shadrac121          Hopfully she takes wat peopl… 2017-12-25 22:27:31\n",
    " 7      7 1fzUjhemoSB1QV7zI7  Si ce propui sa facem cu toa… 2017-12-25 07:41:31\n",
    " 8      8 MinisterOfEducation I don't mean to be impolite,… 2017-12-25 19:28:35\n",
    " 9      9 AabidS10            i dont have a 720p x265 of i… 2017-12-25 13:20:32\n",
    "10     10 S3RG10              \"I'm dying to try Guatemalan… 2017-12-25 00:48:46\n",
    "# ... with 9,990 more rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_clean = posts4 %>% \n",
    "    ...\n",
    "\n",
    "head(posts_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Plot a smooth trend of post length (in characters) over time. Warning: Only plot the smoothing line (i.e. your only geom should be `geom_smooth`); do not plot individual posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
